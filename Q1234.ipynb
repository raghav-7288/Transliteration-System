{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8196746,"sourceType":"datasetVersion","datasetId":4855222},{"sourceId":8213932,"sourceType":"datasetVersion","datasetId":4868284}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# IMPORTS","metadata":{}},{"cell_type":"code","source":"import csv\nimport numpy as np\nimport pandas as pd\nimport os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport heapq\nimport torch.nn.functional as F\nfrom tqdm import tqdm\nfrom torch.nn.utils import clip_grad_norm_\nimport random\nimport wandb\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2024-04-27T21:07:52.694589Z","iopub.execute_input":"2024-04-27T21:07:52.694972Z","iopub.status.idle":"2024-04-27T21:07:55.597320Z","shell.execute_reply.started":"2024-04-27T21:07:52.694934Z","shell.execute_reply":"2024-04-27T21:07:55.596343Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2024-04-27T21:07:55.599387Z","iopub.execute_input":"2024-04-27T21:07:55.599725Z","iopub.status.idle":"2024-04-27T21:07:55.630923Z","shell.execute_reply.started":"2024-04-27T21:07:55.599694Z","shell.execute_reply":"2024-04-27T21:07:55.630093Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"!wandb login 3c81526a5ec348850a4c9d0f852f6631959307ed","metadata":{"execution":{"iopub.status.busy":"2024-04-27T21:07:55.631982Z","iopub.execute_input":"2024-04-27T21:07:55.632227Z","iopub.status.idle":"2024-04-27T21:07:58.498605Z","shell.execute_reply.started":"2024-04-27T21:07:55.632206Z","shell.execute_reply":"2024-04-27T21:07:58.497550Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# PREPROCESSING","metadata":{}},{"cell_type":"code","source":"def loadData(params):\n    language = params['language']\n    dataset_path = params['dataset_path']\n    train_path = os.path.join(dataset_path, language, language + '_train.csv')\n    val_path = os.path.join(dataset_path, language, language + '_valid.csv')\n    test_path = os.path.join(dataset_path, language, language + '_test.csv')\n    train_data = csv.reader(open(train_path,encoding='utf8'))\n    val_data = csv.reader(open(val_path,encoding='utf8'))\n    test_data = csv.reader(open(test_path,encoding='utf8'))\n    train_words , train_translations = [], []\n    val_words , val_translations = [], []\n    test_words , test_translations = [], []\n    pad, start, end ='', '^', '$'\n    \n    for pair in train_data:\n        train_words.append(pair[0] + end)\n        train_translations.append(start + pair[1] + end)\n    for pair in val_data:\n        val_words.append(pair[0] + end)\n        val_translations.append(start + pair[1] + end)\n    for pair in test_data:\n        test_words.append(pair[0] + end)\n        test_translations.append(start + pair[1] + end)\n    \n    train_words , train_translations = np.array(train_words), np.array(train_translations)\n    val_words , val_translations = np.array(val_words), np.array(val_translations)\n    test_words , test_translations = np.array(test_words), np.array(test_translations)\n    input_vocab = set()\n    output_vocab = set()\n    \n    for w in train_words:\n        for c in w:\n            input_vocab.add(c)\n    for w in val_words:\n        for c in w:\n            input_vocab.add(c)\n    for w in test_words:\n        for c in w:\n            input_vocab.add(c)\n            \n    for w in train_translations:\n        for c in w:\n            output_vocab.add(c)\n    for w in val_translations:\n        for c in w:\n            output_vocab.add(c)\n    for w in test_translations:\n        for c in w:\n            output_vocab.add(c)\n    \n    input_vocab.remove(end)\n    output_vocab.remove(start)\n    output_vocab.remove(end)  \n    input_vocab, output_vocab = [pad, start, end] + list(sorted(input_vocab)), [pad, start, end] + list(sorted(output_vocab))\n            \n    input_index = {char: idx for idx, char in enumerate(input_vocab)}\n    output_index = {char: idx for idx, char in enumerate(output_vocab)}\n    # output_index =  dict([(char, idx) for idx, char in enumerate(output_vocab)])\n    input_index_rev = {idx: char for char, idx in input_index.items()}\n    output_index_rev = {idx: char for char, idx in output_index.items()}\n    \n    max_enc_len = max([len(word) for word in np.hstack((train_words, test_words, val_words))])\n    max_dec_len = max([len(word) for word in np.hstack((train_translations, val_translations, test_translations))])\n    max_len = max(max_enc_len, max_dec_len)\n        \n    preprocessed_data = {\n        'SOS' : start,\n        'EOS' : end,\n        'PAD' : pad,\n        'train_words' : train_words,\n        'train_translations' : train_translations,\n        'val_words' : val_words,\n        'val_translations' : val_translations,\n        'test_words' : test_words,\n        'test_translations' : test_translations,\n        'max_enc_len' : max_enc_len,\n        'max_dec_len' : max_dec_len,\n        'max_len' : max_len,\n        'input_index' : input_index,\n        'output_index' : output_index,\n        'input_index_rev' : input_index_rev,\n        'output_index_rev' : output_index_rev\n    }\n    return preprocessed_data","metadata":{"execution":{"iopub.status.busy":"2024-04-27T21:07:58.500019Z","iopub.execute_input":"2024-04-27T21:07:58.500327Z","iopub.status.idle":"2024-04-27T21:07:58.522445Z","shell.execute_reply.started":"2024-04-27T21:07:58.500289Z","shell.execute_reply":"2024-04-27T21:07:58.521343Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def create_tensor(preprocessed_data):\n    input_data = np.zeros((preprocessed_data['max_len'],len(preprocessed_data['train_words'])), dtype = 'int64')\n    output_data = np.zeros((preprocessed_data['max_len'],len(preprocessed_data['train_words'])), dtype = 'int64')\n    \n    val_input_data = np.zeros((preprocessed_data['max_len'],len(preprocessed_data['val_words'])), dtype = 'int64')\n    val_output_data = np.zeros((preprocessed_data['max_len'],len(preprocessed_data['val_words'])), dtype = 'int64')\n    \n    test_input_data = np.zeros((preprocessed_data['max_len'],len(preprocessed_data['test_words'])), dtype = 'int64')\n    test_output_data = np.zeros((preprocessed_data['max_len'],len(preprocessed_data['test_words'])), dtype = 'int64')\n    \n    for idx, (w, t) in enumerate(zip(preprocessed_data['train_words'], preprocessed_data['train_translations'])):\n        for i, char in enumerate(w):\n            input_data[i, idx] = preprocessed_data['input_index'][char]\n        for i, char in enumerate(t):\n            output_data[i, idx] = preprocessed_data['output_index'][char]\n        \n    for idx, (w, t) in enumerate(zip(preprocessed_data['val_words'], preprocessed_data['val_translations'])):\n        for i, char in enumerate(w):\n            val_input_data[i, idx] = preprocessed_data['input_index'][char]\n        for i, char in enumerate(t):\n            val_output_data[i, idx] = preprocessed_data['output_index'][char]\n    \n    for idx, (w, t) in enumerate(zip(preprocessed_data['test_words'], preprocessed_data['test_translations'])):\n        for i, char in enumerate(w):\n            test_input_data[i, idx] = preprocessed_data['input_index'][char]\n        for i, char in enumerate(t):\n            test_output_data[i, idx] = preprocessed_data['output_index'][char]\n    \n    input_data, output_data = torch.tensor(input_data,dtype = torch.int64), torch.tensor(output_data, dtype = torch.int64)\n    val_input_data, val_output_data = torch.tensor(val_input_data,dtype = torch.int64), torch.tensor(val_output_data, dtype = torch.int64)\n    test_input_data, test_output_data = torch.tensor(test_input_data,dtype = torch.int64), torch.tensor(test_output_data, dtype = torch.int64)\n    \n    tensors = {\n        'input_data' : input_data,\n        'output_data' : output_data,\n        'val_input_data' : val_input_data,\n        'val_output_data' : val_output_data, \n        'test_input_data' : test_input_data,\n        'test_output_data' : test_output_data\n    }\n    return tensors","metadata":{"execution":{"iopub.status.busy":"2024-04-27T21:07:58.525481Z","iopub.execute_input":"2024-04-27T21:07:58.525829Z","iopub.status.idle":"2024-04-27T21:07:58.541140Z","shell.execute_reply.started":"2024-04-27T21:07:58.525772Z","shell.execute_reply":"2024-04-27T21:07:58.540114Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# dict = {\n# 'language' : 'hin',\n# # 'dataset_path' : r'C:\\Users\\gragh\\OneDrive\\Desktop\\Codes\\CS6910 DL\\Assignment 3\\DataSet\\aksharantar_sampled',\n# 'dataset_path' : '/kaggle/input/dl-ass3/aksharantar_sampled'\n# }\n# preprocessed_data = loadData(dict)\n# tensors = create_tensor(preprocessed_data)\n\n# print('Input data : ', preprocessed_data['train_words'])\n# print('Output data : ', preprocessed_data['train_translations'])\n# print('Number of samples : ', len(preprocessed_data['train_words']))\n\n# print('Input data : ', preprocessed_data['val_words'])\n# print('Output data : ', preprocessed_data['val_translations'])\n# print('Number of val samples : ', len(preprocessed_data['val_words']))\n\n# print('Input data : ', preprocessed_data['test_words'])\n# print('Output data : ', preprocessed_data['test_translations'])\n# print('Number of test samples : ', len(preprocessed_data['test_words']))\n\n# print('Max incoder length : ', preprocessed_data['max_enc_len'])\n# print('Max incoder length : ', preprocessed_data['max_enc_len'])\n# print('Max length : ', preprocessed_data['max_len'])\n\n# print('Input index length', len(preprocessed_data['input_index']))\n# print('Output index length', len(preprocessed_data['output_index']))\n# print('Input index', preprocessed_data['input_index'])\n# print('Output index', preprocessed_data['output_index'])\n# print('Input index Rev', preprocessed_data['input_index_rev'])\n# print('Output index Rev', preprocessed_data['output_index_rev'])\n\n# print('Input Data', tensors['input_data'].shape)\n# print('Output Data', tensors['output_data'].shape)\n# print('Input Data Val', tensors['val_input_data'].shape)\n# print('Output Data Val', tensors['val_output_data'].shape)\n# print('Input Data Test', tensors['test_input_data'].shape)\n# print('Output Data Test', tensors['test_output_data'].shape)\n\n# print(tensors['input_data'][:,0])\n# print(tensors['output_data'][:,0])","metadata":{"execution":{"iopub.status.busy":"2024-04-27T21:07:58.542466Z","iopub.execute_input":"2024-04-27T21:07:58.542792Z","iopub.status.idle":"2024-04-27T21:07:58.555280Z","shell.execute_reply.started":"2024-04-27T21:07:58.542766Z","shell.execute_reply":"2024-04-27T21:07:58.554437Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Encoder","metadata":{}},{"cell_type":"code","source":"class Encoder(nn.Module): \n    def __init__(self, params, preprocessed_data):\n        super(Encoder, self).__init__()\n        self.cell_type = params['cell_type']\n        self.dropout = nn.Dropout(params['dropout'])\n        self.embedding = nn.Embedding(len(preprocessed_data['input_index']), params['embedding_size'])\n        if self.cell_type == 'RNN':\n            self.cell = nn.RNN(params['embedding_size'], params['hidden_size'], params['num_layers_enc'], dropout = params['dropout'], bidirectional = params['bi_dir'])\n        elif self.cell_type == 'LSTM':\n            self.cell = nn.LSTM(params['embedding_size'], params['hidden_size'], params['num_layers_enc'], dropout = params['dropout'], bidirectional = params['bi_dir'])\n        elif self.cell_type == 'GRU':\n            self.cell = nn.GRU(params['embedding_size'], params['hidden_size'], params['num_layers_enc'], dropout = params['dropout'], bidirectional = params['bi_dir'])\n        else:\n            raise ValueError(\"Invalid type. Choose from 'RNN', 'LSTM', or 'GRU'.\")\n        \n    def forward(self, x):\n        drop_par = self.embedding(x)\n        if self.cell_type == 'LSTM':\n            outputs , (hidden, cell) = self.cell(self.dropout(drop_par))\n            return hidden, cell\n        outputs , hidden = self.cell(self.dropout(drop_par))\n        return hidden","metadata":{"execution":{"iopub.status.busy":"2024-04-27T21:07:58.556591Z","iopub.execute_input":"2024-04-27T21:07:58.556936Z","iopub.status.idle":"2024-04-27T21:07:58.568591Z","shell.execute_reply.started":"2024-04-27T21:07:58.556906Z","shell.execute_reply":"2024-04-27T21:07:58.567664Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Decoder","metadata":{}},{"cell_type":"code","source":"class Decoder(nn.Module):\n    def __init__(self, params, preprocessed_data):\n        super(Decoder, self).__init__()\n        self.cell_type = params['cell_type']\n        self.dropout = nn.Dropout(params['dropout'])\n        self.embedding = nn.Embedding(len(preprocessed_data['output_index']), params['embedding_size'])\n        if self.cell_type == 'RNN':\n            self.cell = nn.RNN(params['embedding_size'], params['hidden_size'], params['num_layers_dec'], dropout = params['dropout'], bidirectional = params['bi_dir'])\n        elif self.cell_type == 'LSTM':\n            self.cell = nn.LSTM(params['embedding_size'], params['hidden_size'], params['num_layers_dec'], dropout = params['dropout'], bidirectional = params['bi_dir'])\n        elif self.cell_type == 'GRU':\n            self.cell = nn.GRU(params['embedding_size'], params['hidden_size'], params['num_layers_dec'], dropout = params['dropout'], bidirectional = params['bi_dir'])\n        else:\n            raise ValueError(\"Invalid type. Choose from 'RNN', 'LSTM', or 'GRU'.\")\n        \n        self.fc = nn.Linear(params['hidden_size'] * 2 if params['bi_dir'] == True else params['hidden_size'], len(preprocessed_data['output_index']))\n\n    def forward(self, x, hidden, cell):\n        embedding = self.embedding(x.unsqueeze(0))\n        if self.cell_type == 'LSTM':\n            outputs, (hidden, cell) = self.cell(self.dropout(embedding), (hidden, cell))\n        else:    \n            outputs, hidden = self.cell(self.dropout(embedding), hidden)\n        predictions = self.fc(outputs).squeeze(0)\n        if self.cell_type == 'LSTM':\n            predictions = F.log_softmax(predictions, dim = 1)\n            return predictions, hidden, cell\n        return predictions, hidden","metadata":{"execution":{"iopub.status.busy":"2024-04-27T21:07:58.569575Z","iopub.execute_input":"2024-04-27T21:07:58.569808Z","iopub.status.idle":"2024-04-27T21:07:58.583607Z","shell.execute_reply.started":"2024-04-27T21:07:58.569788Z","shell.execute_reply":"2024-04-27T21:07:58.582732Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Seq2Seq","metadata":{}},{"cell_type":"code","source":"class Seq2Seq(nn.Module):\n    def __init__(self, encoder, decoder, params,  preprocessed_data):\n        super(Seq2Seq, self).__init__()\n        self.cell_type = params['cell_type']\n        self.decoder, self.encoder  = decoder, encoder\n        self.output_index_len = len(preprocessed_data['output_index'])\n        self.tfr = params['teacher_fr']\n\n    def forward(self, source, target):\n        batch_size, target_len = source.shape[1], target.shape[0]\n        x = target[0]\n        outputs = torch.zeros(target_len, batch_size, self.output_index_len).to(device)\n        if self.cell_type == 'LSTM':\n            hidden, cell = self.encoder(source)\n        else:    \n            hidden = self.encoder(source)\n        for t in range(1, target_len):\n            if self.cell_type == 'LSTM':\n                output, hidden, cell = self.decoder(x, hidden, cell)\n            else:    \n                output, hidden = self.decoder(x, hidden, None)\n            outputs[t], best_guess = output, output.argmax(1)\n            x = best_guess if random.random() >= self.tfr else target[t]\n        return outputs","metadata":{"execution":{"iopub.status.busy":"2024-04-27T21:07:58.584644Z","iopub.execute_input":"2024-04-27T21:07:58.584961Z","iopub.status.idle":"2024-04-27T21:07:58.597051Z","shell.execute_reply.started":"2024-04-27T21:07:58.584938Z","shell.execute_reply":"2024-04-27T21:07:58.596270Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# GET OPTIMIZERS","metadata":{}},{"cell_type":"code","source":"def get_optim(model, params):\n    if params['optimizer'].lower() == 'sgd':\n        optimizer = optim.SGD(model.parameters(), lr = params['learning_rate'], momentum = 0.9)\n    if params['optimizer'].lower() == 'adam':\n        optimizer = optim.Adam(model.parameters(), lr = params['learning_rate'], betas = (0.9, 0.999), eps = 1e-8)\n    if params['optimizer'].lower() == 'rmsprop':\n        optimizer = optim.RMSprop(model.parameters(), lr = params['learning_rate'], alpha = 0.99, eps = 1e-8)\n    if params['optimizer'].lower() == 'adagrad':\n        optimizer = optim.Adagrad(model.parameters(), lr = params['learning_rate'], lr_decay = 0, weight_decay = 0, initial_accumulator_value = 0, eps = 1e-10)\n    return optimizer","metadata":{"execution":{"iopub.status.busy":"2024-04-27T21:07:58.598069Z","iopub.execute_input":"2024-04-27T21:07:58.598367Z","iopub.status.idle":"2024-04-27T21:07:58.610071Z","shell.execute_reply.started":"2024-04-27T21:07:58.598342Z","shell.execute_reply":"2024-04-27T21:07:58.609247Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# GET TOTAL PARAMETERS","metadata":{}},{"cell_type":"code","source":"def get_total_parameters(model):\n    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    return total_params","metadata":{"execution":{"iopub.status.busy":"2024-04-27T21:07:58.611008Z","iopub.execute_input":"2024-04-27T21:07:58.611278Z","iopub.status.idle":"2024-04-27T21:07:58.619093Z","shell.execute_reply.started":"2024-04-27T21:07:58.611257Z","shell.execute_reply":"2024-04-27T21:07:58.618345Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# BEAM SEARCH","metadata":{}},{"cell_type":"code","source":"def beam_search(model, word, preprocessed_data, bw, lp, ct):\n    data = np.zeros((preprocessed_data['max_len']+1, 1), dtype=np.int32)\n    for idx, char in enumerate(word):\n        data[idx, 0] = preprocessed_data['input_index'][char]\n    data[idx + 1, 0] = preprocessed_data['input_index'][preprocessed_data['EOS']]\n    data = torch.tensor(data, dtype=torch.int32).to(device)\n    with torch.no_grad():\n        if ct == 'LSTM':\n           hidden, cell = model.encoder(data)\n        else:\n           hidden = model.encoder(data)\n    output_start = preprocessed_data['output_index'][preprocessed_data['SOS']]\n    out_reshape = np.array(output_start).reshape(1,)\n    hidden_par = hidden.unsqueeze(0)\n    initial_sequence = torch.tensor(out_reshape).to(device)\n    beam = [(0.0, initial_sequence, hidden_par)]\n    for i in range(len(preprocessed_data['output_index'])):\n        candidates = []\n        for score, seq, hidden in beam:\n            if seq[-1].item() == preprocessed_data['output_index'][preprocessed_data['EOS']]:\n                candidates.append((score, seq, hidden))\n                continue\n            reshape_last = np.array(seq[-1].item()).reshape(1, )\n            hdn = hidden.squeeze(0) \n            x = torch.tensor(reshape_last).to(device)\n            if ct == 'LSTM':\n                output, hidden, cell = model.decoder(x, hdn, cell)\n            else:\n                output, hidden = model.decoder(x, hdn, None)\n            topk_probs, topk_tokens = torch.topk(F.softmax(output, dim=1), k = bw)               \n            for prob, token in zip(topk_probs[0], topk_tokens[0]):\n                new_seq = torch.cat((seq, token.unsqueeze(0)), dim=0)\n                ln_ns = len(new_seq)\n                ln_pf = ((ln_ns - 1) / 5)\n                candidate_score = score + torch.log(prob).item() / (ln_pf ** lp)\n                candidates.append((candidate_score, new_seq, hidden.unsqueeze(0)))\n        beam = heapq.nlargest(bw, candidates, key=lambda x: x[0])\n    _, best_sequence, _ = max(beam, key=lambda x: x[0]) \n    prediction = ''.join([preprocessed_data['output_index_rev'][token.item()] for token in best_sequence[1:]])\n    return prediction[:-1]          \n","metadata":{"execution":{"iopub.status.busy":"2024-04-27T21:07:58.620320Z","iopub.execute_input":"2024-04-27T21:07:58.620555Z","iopub.status.idle":"2024-04-27T21:07:58.635508Z","shell.execute_reply.started":"2024-04-27T21:07:58.620535Z","shell.execute_reply":"2024-04-27T21:07:58.634692Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# TRAIN MODEL","metadata":{}},{"cell_type":"code","source":"def train(model, criterion, optimizer, preprocessed_data, tensors, params):\n    train_data, train_result = torch.split(tensors['input_data'], params['batch_size'], dim = 1), torch.split(tensors['output_data'], params['batch_size'], dim = 1)\n    val_data, val_result = torch.split(tensors['val_input_data'], params['batch_size'], dim=1), torch.split(tensors['val_output_data'], params['batch_size'], dim=1)\n    for epoch in range(params['num_epochs']):\n        total_words = 0\n        correct_pred = 0\n        total_loss = 0\n        model.train()\n        with tqdm(total = len(train_data), desc = 'Training') as pbar:\n            for i, (x, y) in enumerate(zip(train_data, train_result)):\n                target, inp_data = y.to(device), x.to(device)\n                optimizer.zero_grad()\n                output = model(inp_data, target)\n                target = target.reshape(-1)\n                output = output.reshape(-1, output.shape[2])\n            \n#                 pad_mask = (target != preprocessed_data['output_index'][preprocessed_data['PAD']])\n#                 target = target[pad_mask]\n#                 output = output[pad_mask]\n                \n                loss = criterion(output, target)\n                loss.backward()\n                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n                optimizer.step()\n                total_loss += loss.item()\n                total_words += target.size(0)\n                correct_pred += torch.sum(torch.argmax(output, dim=1) == target).item()\n                pbar.update(1)\n        train_accuracy = (correct_pred / total_words)*100\n        train_loss = total_loss / len(train_data)\n        model.eval()\n        with torch.no_grad():\n            val_total_loss = 0\n            val_total_words = 0\n            val_correct_pred = 0\n            with tqdm(total = len(val_data), desc = 'Validation') as pbar:\n                for x_val, y_val in zip(val_data, val_result):\n                    target_val, inp_data_val = y_val.to(device), x_val.to(device)\n                    output_val = model(inp_data_val, target_val)\n                    target_val = target_val.reshape(-1)\n                    output_val = output_val.reshape(-1, output_val.shape[2])\n                    \n#                     pad_mask = (target_val != preprocessed_data['output_index'][preprocessed_data['PAD']])\n#                     target_val = target_val[pad_mask]\n#                     output_val = output_val[pad_mask]\n                    \n                    val_loss = criterion(output_val, target_val)\n                    val_total_loss += val_loss.item()\n                    val_total_words += target_val.size(0)\n                    val_correct_pred += torch.sum(torch.argmax(output_val, dim=1) == target_val).item()\n                    pbar.update(1)\n            val_accuracy = (val_correct_pred / val_total_words) * 100\n            val_loss = val_total_loss / len(val_data)\n            \n            correct_pred = 0\n            total_words = len(preprocessed_data['val_words'])\n            with tqdm(total = total_words, desc = 'Beam') as pbar_:\n                for word, translation in zip(preprocessed_data['val_words'], preprocessed_data['val_translations']):\n                    ans = beam_search(model, word, preprocessed_data, params['beam_width'], params['length_penalty'], params['cell_type'])\n                    if ans == translation[1:-1]:\n                        correct_pred += 1\n                    pbar_.update(1)\n        val_accuracy_beam = (correct_pred / total_words) * 100\n        print(f'''Epoch : {epoch+1}\n              Train Accuracy : {train_accuracy:.4f}, Train Loss : {train_loss:.4f}\n              Validation Accuracy Char Level : {val_accuracy:.4f}, Validation Loss : {val_loss:.4f}\n              Validation Accuracy Word Level : {val_accuracy_beam:.4f},  Correctly predicted : {correct_pred}/{total_words}''')\n        if params['w_log']:\n            wandb.log(\n                    {\n                        'epoch': epoch+1,\n                        'training_loss' : train_loss,\n                        'training_accuracy' : train_accuracy,\n                        'validation_loss' : val_loss,\n                        'validation_accuracy_char' : val_accuracy,\n                        'validation_accuracy_word' : val_accuracy_beam,\n                        'correctly_predicted' : correct_pred\n                    }\n                )\n    return model, val_accuracy, val_accuracy_beam","metadata":{"execution":{"iopub.status.busy":"2024-04-27T21:07:58.636946Z","iopub.execute_input":"2024-04-27T21:07:58.637193Z","iopub.status.idle":"2024-04-27T21:07:58.656343Z","shell.execute_reply.started":"2024-04-27T21:07:58.637166Z","shell.execute_reply":"2024-04-27T21:07:58.655481Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# QUESTION 1 : Train Model","metadata":{}},{"cell_type":"markdown","source":"# HYPERPARAMETERS","metadata":{}},{"cell_type":"code","source":"# params = {\n# #     'dataset_path' : r'C:\\Users\\gragh\\OneDrive\\Desktop\\Codes\\CS6910 DL\\Assignment 3\\DataSet\\aksharantar_sampled',\n#     'language' : 'hin',\n#     'dataset_path' : '/kaggle/input/dl-ass3/aksharantar_sampled',\n#     'embedding_size': 256,\n#     'hidden_size': 512,\n#     'num_layers_enc': 2,\n#     'num_layers_dec': 2,\n#     'cell_type': 'GRU',\n#     'dropout': 0.3,\n#     'optimizer' : 'adagrad',\n#     'learning_rate': 0.01,\n#     'batch_size': 32,\n#     'num_epochs': 10,\n#     'teacher_fr' : 0.7,\n#     'length_penalty' : 0.6,\n#     'beam_width': 4,\n#     'bi_dir' : False,\n#     'w_log' : 0\n# }\n# Epoch : 10\n#               Train Accuracy : 28.5620, Train Loss : 0.8019\n#               Validation Accuracy Char Level : 23.6319, Validation Loss : 0.9732\n#               Validation Accuracy Word Level : 40.7227,  Correctly predicted : 1668/4096","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = {\n#     'dataset_path' : r'C:\\Users\\gragh\\OneDrive\\Desktop\\Codes\\CS6910 DL\\Assignment 3\\DataSet\\aksharantar_sampled',\n    'language' : 'hin',\n    'dataset_path' : '/kaggle/input/dl-ass3/aksharantar_sampled',\n    'embedding_size': 256,\n    'hidden_size': 512,\n    'num_layers_enc': 2,\n    'num_layers_dec': 2,\n    'cell_type': 'GRU',\n    'dropout': 0.3,\n    'optimizer' : 'adagrad',\n    'learning_rate': 0.01,\n    'batch_size': 32,\n    'num_epochs': 10,\n    'teacher_fr' : 0.7,\n    'length_penalty' : 0.6,\n    'beam_width': 4,\n    'bi_dir' : False,\n    'w_log' : 0\n}\npreprocessed_data = loadData(params)\ntensors = create_tensor(preprocessed_data)\n\nencoder = Encoder(params, preprocessed_data).to(device)\ndecoder = Decoder(params, preprocessed_data).to(device)\nmodel = Seq2Seq(encoder, decoder, params, preprocessed_data).to(device)  \n# print(model)\n\ncriterion = nn.CrossEntropyLoss(ignore_index = 0)\noptimizer = get_optim(model,params)\n# Print total number of parameters in the model\n# total_parameters = get_total_parameters(model)\n# print(f'Total Trainable Parameters: {total_parameters}')\n\nif params['w_log']:\n    wandb.init(project = 'DL-Assignment-3')\n    wandb.run.name = (\n        'check_c:' + params['cell_type'] +\n        '_e:' + str(params['num_epochs']) +\n        '_es:' + str(params['embedding_size']) +\n        '_hs:' + str(params['hidden_size']) +\n        '_nle:' + str(params['num_layers_enc']) +\n        '_nld:' + str(params['num_layers_dec']) +\n        '_o:' + params['optimizer'] +\n        '_lr:' + str(params['learning_rate']) +\n        '_bs:' + str(params['batch_size']) +\n        '_tf:' + str(params['teacher_fr']) +\n        '_lp:' + str(params['length_penalty']) +\n        '_b:' + str(params['bi_dir']) +\n        '_bw:' + str(params['beam_width'])\n    )\ntrained_model, _, _ = train(model, criterion, optimizer, preprocessed_data, tensors, params)\nif params['w_log']:\n    wandb.finish()","metadata":{"execution":{"iopub.status.busy":"2024-04-27T21:25:51.128212Z","iopub.execute_input":"2024-04-27T21:25:51.128980Z","iopub.status.idle":"2024-04-27T21:53:21.054551Z","shell.execute_reply.started":"2024-04-27T21:25:51.128944Z","shell.execute_reply":"2024-04-27T21:53:21.053672Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"Training: 100%|██████████| 1600/1600 [00:52<00:00, 30.47it/s]\nValidation: 100%|██████████| 128/128 [00:01<00:00, 84.98it/s]\nBeam: 100%|██████████| 4096/4096 [01:49<00:00, 37.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch : 1\n              Train Accuracy : 19.8973, Train Loss : 1.6130\n              Validation Accuracy Char Level : 21.3460, Validation Loss : 1.1907\n              Validation Accuracy Word Level : 25.0244,  Correctly predicted : 1025/4096\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1600/1600 [00:52<00:00, 30.72it/s]\nValidation: 100%|██████████| 128/128 [00:01<00:00, 85.99it/s]\nBeam: 100%|██████████| 4096/4096 [01:50<00:00, 37.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch : 2\n              Train Accuracy : 24.6471, Train Loss : 1.1460\n              Validation Accuracy Char Level : 22.2602, Validation Loss : 1.0997\n              Validation Accuracy Word Level : 31.7627,  Correctly predicted : 1301/4096\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1600/1600 [00:52<00:00, 30.60it/s]\nValidation: 100%|██████████| 128/128 [00:01<00:00, 85.13it/s]\nBeam: 100%|██████████| 4096/4096 [01:52<00:00, 36.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch : 3\n              Train Accuracy : 25.9499, Train Loss : 1.0301\n              Validation Accuracy Char Level : 22.8371, Validation Loss : 1.0378\n              Validation Accuracy Word Level : 34.3018,  Correctly predicted : 1405/4096\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1600/1600 [00:52<00:00, 30.63it/s]\nValidation: 100%|██████████| 128/128 [00:01<00:00, 85.46it/s]\nBeam: 100%|██████████| 4096/4096 [01:51<00:00, 36.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch : 4\n              Train Accuracy : 26.6657, Train Loss : 0.9671\n              Validation Accuracy Char Level : 23.1228, Validation Loss : 1.0073\n              Validation Accuracy Word Level : 36.3770,  Correctly predicted : 1490/4096\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1600/1600 [00:52<00:00, 30.36it/s]\nValidation: 100%|██████████| 128/128 [00:01<00:00, 85.48it/s]\nBeam: 100%|██████████| 4096/4096 [01:50<00:00, 36.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch : 5\n              Train Accuracy : 27.1622, Train Loss : 0.9226\n              Validation Accuracy Char Level : 23.3778, Validation Loss : 0.9913\n              Validation Accuracy Word Level : 37.5488,  Correctly predicted : 1538/4096\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1600/1600 [00:51<00:00, 30.95it/s]\nValidation: 100%|██████████| 128/128 [00:01<00:00, 86.87it/s]\nBeam: 100%|██████████| 4096/4096 [01:51<00:00, 36.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch : 6\n              Train Accuracy : 27.5605, Train Loss : 0.8896\n              Validation Accuracy Char Level : 23.4456, Validation Loss : 0.9795\n              Validation Accuracy Word Level : 38.0371,  Correctly predicted : 1558/4096\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1600/1600 [00:51<00:00, 30.89it/s]\nValidation: 100%|██████████| 128/128 [00:01<00:00, 87.73it/s]\nBeam: 100%|██████████| 4096/4096 [01:51<00:00, 36.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch : 7\n              Train Accuracy : 27.8257, Train Loss : 0.8652\n              Validation Accuracy Char Level : 23.4384, Validation Loss : 0.9828\n              Validation Accuracy Word Level : 39.2334,  Correctly predicted : 1607/4096\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1600/1600 [00:51<00:00, 30.96it/s]\nValidation: 100%|██████████| 128/128 [00:01<00:00, 81.43it/s]\nBeam: 100%|██████████| 4096/4096 [01:50<00:00, 36.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch : 8\n              Train Accuracy : 28.1029, Train Loss : 0.8417\n              Validation Accuracy Char Level : 23.5560, Validation Loss : 0.9722\n              Validation Accuracy Word Level : 39.5752,  Correctly predicted : 1621/4096\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1600/1600 [00:51<00:00, 30.88it/s]\nValidation: 100%|██████████| 128/128 [00:01<00:00, 87.22it/s]\nBeam: 100%|██████████| 4096/4096 [01:53<00:00, 36.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch : 9\n              Train Accuracy : 28.3662, Train Loss : 0.8187\n              Validation Accuracy Char Level : 23.5740, Validation Loss : 0.9726\n              Validation Accuracy Word Level : 40.1123,  Correctly predicted : 1643/4096\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1600/1600 [00:51<00:00, 30.93it/s]\nValidation: 100%|██████████| 128/128 [00:01<00:00, 86.03it/s]\nBeam: 100%|██████████| 4096/4096 [01:52<00:00, 36.47it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch : 10\n              Train Accuracy : 28.5620, Train Loss : 0.8019\n              Validation Accuracy Char Level : 23.6319, Validation Loss : 0.9732\n              Validation Accuracy Word Level : 40.7227,  Correctly predicted : 1668/4096\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Prediction","metadata":{}},{"cell_type":"code","source":"def predict(model, word, preprocessed_data, params):\n    data = np.zeros((preprocessed_data['max_len'] + 1,1), dtype= int)\n    pred = ''\n    for t, char in enumerate(word):\n        data[t, 0] = preprocessed_data['input_index'][char]\n    data[(t+1),0] = preprocessed_data['input_index'][preprocessed_data['EOS']]\n    data = torch.tensor(data,dtype = torch.int64).to(device)\n    with torch.no_grad():\n        if params['cell_type'] == 'LSTM':\n            hidden, cell = model.encoder(data)\n        else:\n            hidden = model.encoder(data)\n    x = torch.tensor([preprocessed_data['output_index'][preprocessed_data['SOS']]]).to(device)\n    for t in range(1, len(preprocessed_data['output_index'])):\n        if params['cell_type'] == 'LSTM':\n            output, hidden, cell = model.decoder(x, hidden, cell)\n        else:\n            output, hidden = model.decoder(x, hidden, None)\n        character = preprocessed_data['output_index_rev'][output.argmax(1).item()]\n        if character != preprocessed_data['EOS']:\n            pred = pred + character\n        else:\n            break\n        x = torch.tensor([output.argmax(1)]).to(device)        \n    return pred\n\nwords = ['harsh', 'iit', 'madras', 'nirav', 'nishchal', 'nishant', 'neymar', 'neha', 'raghav', 'rahul', 'rohit', 'hahahahaha', 'ohohohoh']\nprint('################################## using predict function ############################################################')\nfor w in words:\n    output_sequence = predict(trained_model, w, preprocessed_data, params)\n    print(w,'->',output_sequence)\nfor w in preprocessed_data['val_words'][:10]:\n    output_sequence = predict(trained_model, w[:-1], preprocessed_data, params)\n    print(w,'->',output_sequence)\nprint('################################## using beam ############################################################')\nfor w in words:\n    output_sequence = beam_search(trained_model, w, preprocessed_data, params['beam_width'], params['length_penalty'], params['cell_type'])\n    print(w,'->',output_sequence)\nfor w in preprocessed_data['val_words'][:10]:\n    output_sequence = beam_search(trained_model, w, preprocessed_data, params['beam_width'], params['length_penalty'], params['cell_type'])\n    print(w,'->',output_sequence)        \n","metadata":{"execution":{"iopub.status.busy":"2024-04-27T22:07:06.140681Z","iopub.execute_input":"2024-04-27T22:07:06.141094Z","iopub.status.idle":"2024-04-27T22:07:06.878182Z","shell.execute_reply.started":"2024-04-27T22:07:06.141063Z","shell.execute_reply":"2024-04-27T22:07:06.877144Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"################################## using predict ############################################################\nharsh -> हर्ष\niit -> आईआईटी\nmadras -> मदरास\nnirav -> निरव\nnishchal -> निश्चल\nnishant -> निशंत\nneymar -> नेमार\nneha -> नेहा\nraghav -> रघव\nrahul -> राहुल\nrohit -> रोहित\nhahahahaha -> हहहहहाहा\nohohohoh -> ओहोहोह\njaisawal$ -> जसावाल\nbajai$ -> बजाई\nsanghthan$ -> संघठन\nhaiwaan$ -> हैवान\nnilgiri$ -> निलगिरी\ndrutgrami$ -> द्रत्ग्रामी\njhadapon$ -> झड़पों\nnakronda$ -> नकरोंडा\neesl$ -> ईएसआईएल\nbachta$ -> बचता\n################################## using beam ############################################################\nharsh -> हर्ष\niit -> आईआईटी\nmadras -> मदरास\nnirav -> निरव\nnishchal -> निश्चल\nnishant -> निशंत\nneymar -> नेमार\nneha -> नेहा\nraghav -> रघव\nrahul -> राहुल\nrohit -> रोहित\nhahahahaha -> हहहहहाहा\nohohohoh -> ओहोहोह\njaisawal$ -> जैसावाल\nbajai$ -> बजाई\nsanghthan$ -> संघठन\nhaiwaan$ -> हैवान\nnilgiri$ -> निलगिरी\ndrutgrami$ -> द्रत्ग्रामी\njhadapon$ -> झड़पों\nnakronda$ -> नकरोंडा\neesl$ -> ईईएसएल\nbachta$ -> बचता\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Question 4 : Test Accuracy","metadata":{}},{"cell_type":"code","source":"trained_model.eval()\ncorrect_pred = 0\nwords, translations, predictions, results = [], [], [], []\ntotal_words = len(preprocessed_data['test_words'])\nwith tqdm(total = total_words, desc = 'Test_beam') as pbar_:\n    for word, translation in zip(preprocessed_data['test_words'], preprocessed_data['test_translations']):\n        ans = beam_search(trained_model, word, preprocessed_data, params['beam_width'], params['length_penalty'], params['cell_type'])\n        words.append(word[:-1])\n        translations.append(translation[1:-1])\n        predictions.append(ans)\n        if ans == translation[1:-1]:\n            correct_pred += 1\n            results.append('Yes')\n        else:\n            results.append('No')\n        pbar_.update(1)\ntest_accuracy = (correct_pred / total_words) * 100\nprint(f'''Test Accuracy : {test_accuracy:.4f}, Correctly predicted : {correct_pred}/{total_words}''')\n\n# Logging Results\nlog = {'Word': words, 'Translation' : translations, 'Prediction' : predictions, 'Result' : results}\npath = '/kaggle/working/predictions_vanilla.csv'\ndata_frame = pd.DataFrame(log)\ndata_frame.to_csv(path, header = True, index = False)\npd.DataFrame(log)","metadata":{"execution":{"iopub.status.busy":"2024-04-27T22:11:06.568928Z","iopub.execute_input":"2024-04-27T22:11:06.569641Z","iopub.status.idle":"2024-04-27T22:13:12.916921Z","shell.execute_reply.started":"2024-04-27T22:11:06.569604Z","shell.execute_reply":"2024-04-27T22:13:12.915972Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"Test_beam: 100%|██████████| 4096/4096 [02:06<00:00, 32.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Accuracy : 38.6475, Correctly predicted : 1583/4096\n","output_type":"stream"},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"              Word  Translation    Prediction Result\n0          thermax      थरमैक्स       थर्मक्स     No\n1        sikhaaega      सिखाएगा       सिखाएगा    Yes\n2            learn         लर्न          लीरन     No\n3         twitters     ट्विटर्स      ट्विटर्स    Yes\n4      tirunelveli  तिरुनेलवेली  तिरुनेलेवीली     No\n...            ...          ...           ...    ...\n4091       saflata       सफ़लता         सफलता     No\n4092        shbana        शबाना        श्बाना     No\n4093  khaatootolaa     खातूटोला      खातूतोला     No\n4094    shivastava     शिवास्तव      शिवस्तवा     No\n4095  preranapuree  प्रेरणापुरी   प्रेरानपुरी     No\n\n[4096 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>Translation</th>\n      <th>Prediction</th>\n      <th>Result</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>thermax</td>\n      <td>थरमैक्स</td>\n      <td>थर्मक्स</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>sikhaaega</td>\n      <td>सिखाएगा</td>\n      <td>सिखाएगा</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>learn</td>\n      <td>लर्न</td>\n      <td>लीरन</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>twitters</td>\n      <td>ट्विटर्स</td>\n      <td>ट्विटर्स</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>tirunelveli</td>\n      <td>तिरुनेलवेली</td>\n      <td>तिरुनेलेवीली</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4091</th>\n      <td>saflata</td>\n      <td>सफ़लता</td>\n      <td>सफलता</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>4092</th>\n      <td>shbana</td>\n      <td>शबाना</td>\n      <td>श्बाना</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>4093</th>\n      <td>khaatootolaa</td>\n      <td>खातूटोला</td>\n      <td>खातूतोला</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>4094</th>\n      <td>shivastava</td>\n      <td>शिवास्तव</td>\n      <td>शिवस्तवा</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>4095</th>\n      <td>preranapuree</td>\n      <td>प्रेरणापुरी</td>\n      <td>प्रेरानपुरी</td>\n      <td>No</td>\n    </tr>\n  </tbody>\n</table>\n<p>4096 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# QUESTION 2 : Tuning Hyperparameters","metadata":{}},{"cell_type":"code","source":"# sweep_config = {\n#             'name': 'sweep 1 and 1.1 : random',\n#             'method': 'random',\n#             'metric': { 'goal': 'maximize','name': 'Accuracy'},\n#             'parameters': \n#                 {\n#                     'num_epochs': {'values': [10]},\n#                     'cell_type': {'values': ['RNN', 'LSTM', 'GRU']},\n#                     'embedding_size': {'values': [128, 256, 512]},\n#                     'hidden_size': {'values': [128, 256, 512]},\n#                     'num_layers': {'values': [1, 2, 3]},\n#                     'dropout': {'values': [0.3, 0.5, 0.7]},\n#                     'optimizer' : {'values' : ['adam', 'sgd', 'rmsprop', 'adagrad']},\n#                     'learning_rate': {'values': [0.001, 0.005, 0.01, 0.1]},\n#                     'batch_size': {'values': [32, 64]},\n#                     'teacher_fr' : {'values': [0.3, 0.5, 0.7]},\n#                     'length_penalty' : {'values': [0.4, 0.5, 0.6]},\n#                     'bi_dir' : {'values': [True, False]},\n#                     'beam_width': {'values': [1, 2, 3]}\n#                 }\n#             }","metadata":{"execution":{"iopub.status.busy":"2024-04-27T21:09:41.942842Z","iopub.status.idle":"2024-04-27T21:09:41.943160Z","shell.execute_reply.started":"2024-04-27T21:09:41.942995Z","shell.execute_reply":"2024-04-27T21:09:41.943008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sweep_config = {\n#             'name': 'sweep 2 : bayes',\n#             'method': 'bayes',\n#             'metric': { 'goal': 'maximize','name': 'Accuracy'},\n#             'parameters': \n#                 {\n#                     'num_epochs': {'values': [10]},\n#                     'cell_type': {'values': ['LSTM', 'GRU']},\n#                     'embedding_size': {'values': [128, 256]},\n#                     'hidden_size': {'values': [128, 256, 512]},\n#                     'num_layers': {'values': [1, 2, 3]},\n#                     'dropout': {'values': [0.3, 0.5]},\n#                     'optimizer' : {'values' : ['adam']},\n#                     'learning_rate': {'values': [0.001, 0.005, 0.01, 0.1]},\n#                     'batch_size': {'values': [32, 64]},\n#                     'teacher_fr' : {'values': [0.3, 0.5, 0.7]},\n#                     'length_penalty' : {'values': [0.5, 0.6]},\n#                     'bi_dir' : {'values': [True]},\n#                     'beam_width': {'values': [1]}\n#                 }\n#             }","metadata":{"execution":{"iopub.status.busy":"2024-04-27T21:09:41.944265Z","iopub.status.idle":"2024-04-27T21:09:41.944621Z","shell.execute_reply.started":"2024-04-27T21:09:41.944456Z","shell.execute_reply":"2024-04-27T21:09:41.944470Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_sweep():\n    init = wandb.init(project = 'DL-Assignment-3')\n    config = init.config\n    params = {\n        'language' : 'hin',\n        'dataset_path' : '/kaggle/input/dl-ass3/aksharantar_sampled',\n        'num_epochs': config.num_epochs,\n        'cell_type': config.cell_type,\n        'embedding_size': config.embedding_size,\n        'hidden_size': config.hidden_size,\n        'num_layers_enc': config.num_layers,\n        'num_layers_dec': config.num_layers,\n        'dropout': config.dropout,\n        'optimizer' : config.optimizer,\n        'learning_rate': config.learning_rate,\n        'batch_size': config.batch_size,\n        'teacher_fr' : config.teacher_fr,\n        'length_penalty' : config.length_penalty,\n        'bi_dir' : config.bi_dir,\n        'beam_width' : config.beam_width,\n        'w_log' : 1\n    }\n    \n    wandb.run.name = (\n        'Q2_c:' + params['cell_type'] +\n        '_e' + str(params['num_epochs']) +\n        '_es:' + str(params['embedding_size']) +\n        '_hs:' + str(params['hidden_size']) +\n        '_nle:' + str(params['num_layers_enc']) +\n        '_nld:' + str(params['num_layers_dec']) +\n        '_o:' + params['optimizer'] +\n        '_lr:' + str(params['learning_rate']) +\n        '_bs:' + str(params['batch_size']) +\n        '_tf:' + str(params['teacher_fr']) +\n        '_lp:' + str(params['length_penalty']) +\n        '_b:' + str(params['bi_dir']) +\n        '_bw:' + str(params['beam_width'])\n    )\n    preprocessed_data = loadData(params)\n    tensors = create_tensor(preprocessed_data)\n    \n    encoder = Encoder(params, preprocessed_data).to(device)\n    decoder = Decoder(params, preprocessed_data).to(device)\n    model = Seq2Seq(encoder, decoder, params, preprocessed_data).to(device) \n    \n    criterion = nn.CrossEntropyLoss(ignore_index = 0)\n    optimizer = get_optim(model,params)\n    _, _, v_acc_beam = train(model, criterion, optimizer, preprocessed_data, tensors, params)\n    wandb.log({'Accuracy': v_acc_beam})","metadata":{"execution":{"iopub.status.busy":"2024-04-27T21:09:41.946203Z","iopub.status.idle":"2024-04-27T21:09:41.946537Z","shell.execute_reply.started":"2024-04-27T21:09:41.946372Z","shell.execute_reply":"2024-04-27T21:09:41.946386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sweep_id = wandb.sweep(sweep_config, project='DL-Assignment-3')\n# wandb.agent(sweep_id, run_sweep, count = 30)\n# wandb.finish()","metadata":{"execution":{"iopub.status.busy":"2024-04-27T21:09:41.947276Z","iopub.status.idle":"2024-04-27T21:09:41.947619Z","shell.execute_reply.started":"2024-04-27T21:09:41.947461Z","shell.execute_reply":"2024-04-27T21:09:41.947474Z"},"trusted":true},"execution_count":null,"outputs":[]}]}